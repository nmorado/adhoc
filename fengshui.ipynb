{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fengshui.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nmorado/adhoc/blob/master/fengshui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb5A1m6lf6UG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "4732b614-f0b8-4497-c62c-f0d7f2c9e3c4"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pickle"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOl74OUc-_PR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "execution_path = os.getcwd()\n",
        "\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWNPYpmlBdgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n2_YB5IhxjW",
        "colab_type": "text"
      },
      "source": [
        "# load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIixzP3Ch2yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_training_X = pickle.load(open(\"training.X.pickle\", \"rb\"))\n",
        "_training_y = pickle.load(open(\"training.y.pickle\", \"rb\"))\n",
        "_test_X = pickle.load(open(\"test.X.pickle\", \"rb\"))\n",
        "_test_y = pickle.load(open(\"test.y.pickle\", \"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi-4xLqynFAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "c394539f-f2dc-4005-f3c0-5023458bd7d6"
      },
      "source": [
        "# image normalization\n",
        "_training_X = _training_X / 255.0\n",
        "_test_X = _test_X / 255.0\n",
        "\n",
        "# build convolutional network\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[500, 500, 3]))\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"sparse_categorical_accuracy\"])\n",
        "\n",
        "model.fit(_training_X, _training_y, epochs=5)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(_test_X, _test_y)\n",
        "\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 500, 500, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 500, 500, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 250, 250, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 250, 250, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 125, 125, 64)      0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1000000)           0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               128000128 \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 128,030,058\n",
            "Trainable params: 128,030,058\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 65 samples\n",
            "Epoch 1/5\n",
            "65/65 [==============================] - 64s 978ms/sample - loss: 15.1974 - sparse_categorical_accuracy: 0.2154\n",
            "Epoch 2/5\n",
            "65/65 [==============================] - 59s 901ms/sample - loss: 64.8069 - sparse_categorical_accuracy: 0.2154\n",
            "Epoch 3/5\n",
            "65/65 [==============================] - 58s 899ms/sample - loss: 8.4848 - sparse_categorical_accuracy: 0.2000\n",
            "Epoch 4/5\n",
            "65/65 [==============================] - 58s 898ms/sample - loss: 2.8489 - sparse_categorical_accuracy: 0.2923\n",
            "Epoch 5/5\n",
            "65/65 [==============================] - 59s 909ms/sample - loss: 1.4678 - sparse_categorical_accuracy: 0.6154\n",
            "6/6 [==============================] - 1s 225ms/sample - loss: 1.2232 - sparse_categorical_accuracy: 0.5000\n",
            "Test accuracy: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhZgh7RE7e0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('fengshui.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7QZeWga_ZME",
        "colab_type": "text"
      },
      "source": [
        "Test an image\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAn7x0qm_blE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be984945-4042-4c62-e076-c346632d73f6"
      },
      "source": [
        "IMG_RES = (500, 500)\n",
        "# img = 'studyroom.jpg'\n",
        "img = 'livingroom.png'\n",
        "\n",
        "test_image = image.load_img(img, target_size=IMG_RES)\n",
        "\n",
        "img_array = cv2.imread(img, cv2.IMREAD_COLOR)\n",
        "new_array = cv2.resize(img_array, IMG_RES)\n",
        "\n",
        "input = np.array(new_array).reshape(-1, IMG_RES[0], IMG_RES[1], 3)\n",
        "input = input/255\n",
        "\n",
        "\n",
        "result = model.predict_classes(input)\n",
        "print(result)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjBXn4yOBlS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}